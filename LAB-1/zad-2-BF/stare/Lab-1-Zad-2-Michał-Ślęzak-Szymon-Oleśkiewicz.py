# -*- coding: utf-8 -*-
"""Lab1-Zad-2-Michał-Ślęzak-Szymon-Oleśkiewicz.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uV-wHsoDkI6Nm5TRsm5vs6S-2WEvZDYr
"""



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

np.random.seed(45)

"""# Wczytanie danych z pliku txt z separatorem \t i IEDA"""

body_fat_df = pd.read_csv('chhp.txt', sep="\t")

body_fat_df.head()

body_fat_df.info()

body_fat_df.describe()

body_fat_df.isna().sum()

"""Jak widać, nie ma brakujących danych :)

# EDA

**1. Sprawdzenie korelacji między zmiennymi** - pierwsza metoda eliminacji zmiennych
"""

plt.figure(figsize=(10,8))
sns.heatmap(body_fat_df.corr(), annot=True, cmap='coolwarm', center=0, fmt='.2f')
plt.title('Macierz korelacji')
plt.show()

"""**Obserwacje:** Jak widać na powyższej wizualizacji macierzy korelacji, sugerowana jest silna korelacja między zmienną zależną - poziomem tkanki tłuszczowej a zmiennymi objaśniającymi - brzuchem czy talią. Ponadto, macierz korelacji sugeruje silną korelację między predyktorami o największej korelacji ze zmienną zależną - brzuch i talia, po czym można wnioskować, że eliminacja wsteczna wyeliminuje któryś z nich ze względu na to, że de facto mierzą to samo a chcemy uniknąć wieloliniowości i redundantnych danych (multikolinearność). Warto też zauważyć, że między procentem BF a gęstością występuje niemalże idealna korelacja ujemna, czyli im większy poziom tkanki tłuszczowej, tym mniejsza gęstość.

**2. Sprawdzenie na wykresach (liniowość)**
"""

for col in body_fat_df.columns:
    plt.figure()
    sns.scatterplot(x=body_fat_df[col], y=body_fat_df['Pct.BF'])
    plt.title(f'Pct.BF vs {col}')
    plt.show()

"""**Obserwacje:** Analiza wykresów rozrzutu między zmienną zależną (bodyfat %) a zmiennymi objaśniającymi nie wykazała konkretnego wzorca kształtu związków między nimi. Widać jedynie silną odwrotną proporcjonalność gęstości i BF, co świadczy też, po wykresie o zależności liniowej. Wykresy Abdomen vs BF i Waist vs BF sugerują, że będzie to liniowa relacja.

# Model z Abdomen vs BF
Z analizy macierzy korelacji wynika występowanie silnej multikolinearności między zmiennymi Abdomen i Waist (korelacja = 1.0). Aby uniknąć redundancji, zdecydowałem się zbudować model oparty o Abdomen. We dodac!!!
"""

def calculate_std(y_test, y_pred, df):
    sse = np.sum((y_test - y_pred) ** 2)
    df_total = len(y_test) - df - 1
    # print(len(y_test), df)
    return np.sqrt(sse / df_total)


def calculate_we(y_test, y_pred, df):
  return (calculate_std(y_test, y_pred, df) / np.mean(y_test)) * 100

"""# Model z Abdomen vs BF

"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, mean_absolute_percentage_error
import statsmodels.api as sm

X = body_fat_df['Abdomen']
y = body_fat_df['Pct.BF']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)
X_train, X_test = sm.add_constant(X_train), sm.add_constant(X_test)

model_abdomen = sm.OLS(y_train, X_train).fit()
y_pred = model_abdomen.predict(X_test)

print(model_abdomen.summary())
print(f"Współczynnik zmienności We: {calculate_we(y_test, y_pred, model_abdomen.df_model)}")

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = root_mean_squared_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)

print(f"MSE: {mse}")
print(f"MAE: {mae}")
print(f"RMSE: {rmse}")
print(f"MAPE: {mape}")

X_train_sorted = X_train.sort_values(by='Abdomen')
prediction_results = model_abdomen.get_prediction(X_train_sorted)
summary_frame = prediction_results.summary_frame(alpha=0.05) # 95%

plt.figure(figsize=(12, 7))
plt.scatter(X_train['Abdomen'], y_train, color='blue', alpha=0.5, label='Dane treningowe')
plt.plot(X_train_sorted['Abdomen'], summary_frame['mean'], color='red', linewidth=2, label='Linia regresji')
plt.fill_between(X_train_sorted['Abdomen'],
                 summary_frame['mean_ci_lower'],
                 summary_frame['mean_ci_upper'],
                 color='red', alpha=0.2, label='95% Przedział ufności')

plt.title('Dopasowanie modelu do danych: Abdomen vs Pct. BF')
plt.xlabel('Abdomen')
plt.ylabel('Pct.BF')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

"""**Obserwacje:** Model nie dopasowuje się najlepiej do danych treningowych, biorąc pod uwagę R^2 czy chociażby współczynnik dopasowania We, któy wynosi > 20%. Cechuje go przeciętna zmienność.
**Wykres dopasowania modelu do danych treningowych** *wskazuje silną, dodatnią korelację liniową między obwodem brzucha a procentem tkanki tłuszczowej. Rozrzut niektórych wartości rzeczywistych poza przedział ufności może świadczyć o tym, że model ten nie jest najlepszy oraz że istnieją inne czynniki, nie tylko Abdomen, które wpływają na poziom tkanki tłuszczowej i które należy uwzględnić, aby poprawić dopasowanie.*

**Tabela rzeczywista wartość vs predykcja**
"""

from tabulate import tabulate
import scipy.stats as stats

# print(tabulate(zip(X_test['Abdomen'], y_test, y_pred), headers=['Abdomen', 'Obserwacja Pct. BF', 'Prognoza Pct. BF']))
prediction_obj = model_abdomen.get_prediction(X_test)
summary_table = prediction_obj.summary_frame(alpha=0.05)

df = model_abdomen.df_resid  # stopnie swobody (n - k - 1)
t_crit = stats.t.ppf(1 - 0.05/2, df)

results_df = pd.DataFrame({
    'Abdomen': X_test['Abdomen'],
    'Obserwacja Pct. BF': y_test,
    'Prognoza Pct. BF': summary_table['mean'].values,
    'Bład standardowy': summary_table['mean_se'].values,
    'Przedział 95% (dolny)': summary_table['obs_ci_lower'].values, # przedzial predykcji
    'Przedział 95% (górny)': summary_table['obs_ci_upper'].values # przedzial predykcji
})

results_df.reset_index(inplace=True, drop=True)

print(f"\n\nWartość t-Studenta dla 95% przedziału: {t_crit:.3f}")
results_df

"""**Obserwacje:** Obliczone ME, MAE, RMSE sugerują, że zdolność modelu do predykcji opartego na tej jednej zmiennej nie jest najlepsza. Analiza i zestawienie danych rzeczywistych z prognozami sugeruje, że uwzględnienie tylko jednej zmiennej objaśniającej - Abdomen może być niewystarczające. Analiza przedziałów predykcji wykazała istotne ograniczenia tego modelu prostego. Warto zauważyć też relatywnie szeroki przedział dla poszczególnych rekordów, co może w praktyce nie mieć żadnej wartości biznesowej ze względu na tak duży rozrzut. Świadczy to o tym, że pojedyncza zmienna objaśniająca, w tym przypadku Abdomen, może nie być wystarczająca do precyzyjnego opisania tak złożonego parametru, jakim jest zawartość tkanki tłuszczowej, mimo że większość danych testowych mieści się w przedziałach predykcji."""

plot_df = results_df.sort_values(['Abdomen'])

plt.figure(figsize=(12, 7))
plt.scatter(results_df['Abdomen'], results_df['Obserwacja Pct. BF'],
            color='blue', alpha=0.5, label='Dane testowe')
plt.plot(plot_df['Abdomen'], plot_df['Prognoza Pct. BF'],
         color='red', lw=2, label='Linia regresji')
plt.fill_between(plot_df['Abdomen'],
                 plot_df['Przedział 95% (dolny)'],
                 plot_df['Przedział 95% (górny)'],
                 color='red', alpha=0.15, label='95% Przedział Predykcji')

plt.axhline(0, color='black', linewidth=1, linestyle='--')
plt.title('Predykcja na zbiorze testowym z przedziałem predykcji')
plt.xlabel('Abdomen')
plt.ylabel('Pct. BF')
plt.legend()
plt.grid(True, linestyle=':', alpha=0.6)
plt.show()

"""# Model z Density vs BF"""

X = body_fat_df['Density']
y = body_fat_df['Pct.BF']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=46)
X_train, X_test = sm.add_constant(X_train), sm.add_constant(X_test)

model_density = sm.OLS(y_train, X_train).fit()
print(model_density.summary())
print(f"Współczynnik zmienności We: {calculate_we(y_test, y_pred, model_density.df_model)}")

y_pred = model_density.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = root_mean_squared_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)

print(f"MSE: {mse}")
print(f"MAE: {mae}")
print(f"RMSE: {rmse}")
print(f"MAPE: {mape}")

X_train_sorted = X_train.sort_values(by='Density')
prediction_results = model_density.get_prediction(X_train_sorted)
summary_frame = prediction_results.summary_frame(alpha=0.05) # 95%

df = model_density.df_resid  # stopnie swobody (n - k - 1)
t_crit = stats.t.ppf(1 - 0.05/2, df)

results_df = pd.DataFrame({
    'Density': X_test['Density'],
    'Obserwacja Pct. BF': y_test,
    'Prognoza Pct. BF': summary_table['mean'].values,
    'Bład standardowy': summary_table['mean_se'].values,
    'Przedział 95% (dolny)': summary_table['obs_ci_lower'].values, # przedzial predykcji
    'Przedział 95% (górny)': summary_table['obs_ci_upper'].values # przedzial predykcji
})

plt.figure(figsize=(12, 7))
plt.scatter(X_train['Density'], y_train, color='blue', alpha=0.5, label='Dane treningowe')
plt.plot(X_train_sorted['Density'], summary_frame['mean'], color='red', linewidth=2, label='Linia regresji')
plt.fill_between(X_train_sorted['Density'],
                 summary_frame['mean_ci_lower'],
                 summary_frame['mean_ci_upper'],
                 color='red', alpha=0.2, label='95% Przedział ufności')

plt.title('Dopasowanie modelu do danych: Density vs Pct. BF')
plt.xlabel('Density')
plt.ylabel('Pct.BF')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

"""**Obserwacje:** Model dobrze dopasowuje, niemal idealne, z R^2 = 0,969 i We = 1,87% (w przedziale [0%, 25%]-co potwierdza dobre dopasowanie modelu, małą zmienność). Model wyjaśnia 97% zmienności Pct.BF, a błędy predykcji stanowią tylko 2%, co świadczy o bardzo niskiej zmienności. RMSE na poziomie 0.331 oznacza typowy błąd 0,331% poziomu tkanki tłuszczowej, który jest praktycznie pomijalny, natomiast MAPE = 1,8% wskazuje, że nasz model "myli się" o 1,8% prawdziwej wartości Pct. BF. O jakości dopasowania danych i jakości predykcji dowodzi także wykres dopasowania oraz wykres predykcji, na którym dane treningowe oraz testowe - w przypadku wykresu predykcji niemalże idealnie pokrywają się z linią regresji.

Zmienna Density zostanie wykluczona z dalszych analiz, mimo niemalże idealnych metryk. Powodem jest brak realnej wartości biznesowej - gęstość ciała jest niepraktyczna do pomiaru w warunkach, np. gabinetowych. W realnych scenariuszach, takich jak wizyta pacjenta u lekarza, preferujemy łatwo mierzone predyktory, które zachowują wysoką jakość predykcji przy znacznie większej prostocie pomiaru.
"""

prediction_obj = model_density.get_prediction(X_test)
summary_table = prediction_obj.summary_frame(alpha=0.05)

df = model_density.df_resid  # stopnie swobody (n - k - 1)
t_crit = stats.t.ppf(1 - 0.05/2, df)

results_df = pd.DataFrame({
    'Density': X_test['Density'],
    'Obserwacja Pct. BF': y_test,
    'Prognoza Pct. BF': summary_table['mean'].values,
    'Bład standardowy': summary_table['mean_se'].values,
    'Przedział 95% (dolny)': summary_table['obs_ci_lower'].values, # przedzial predykcji
    'Przedział 95% (górny)': summary_table['obs_ci_upper'].values # przedzial predykcji
})

results_df.reset_index(inplace=True, drop=True)

print(f"\n\nWartość t-Studenta dla 95% przedziału: {t_crit:.3f}")
results_df

plot_df = results_df.sort_values('Density')

plt.figure(figsize=(12, 7))
plt.scatter(results_df['Density'], results_df['Obserwacja Pct. BF'],
            color='blue', alpha=0.5, label='Dane testowe')
plt.plot(plot_df['Density'], plot_df['Prognoza Pct. BF'],
         color='red', lw=2, label='Linia regresji')
plt.fill_between(plot_df['Density'],
                 plot_df['Przedział 95% (dolny)'],
                 plot_df['Przedział 95% (górny)'],
                 color='red', alpha=0.15, label='95% Przedział Predykcji')

plt.title('Predykcja na zbiorze testowym z przedziałem predykcji')
plt.xlabel('Density')
plt.ylabel('Pct. BF')
plt.legend()
plt.grid(True, linestyle=':', alpha=0.6)
plt.show()

"""# Procedura eliminacji zmiennych wraz z uzasadnieniem
**Backward Feature Elimination** - jedna z najpopularniejszych metod eliminacji zmiennych, wybrałem ją ze względu na "prostotę". Zaczynamy od wszystkich zmiennych i budujemy nasz model. Następnie usuwamy z listy cech zmienną, która daje najlepszą wartość miary oceny. Proces ten jest kontynuowany aż do osiągnięcia zadanego kryterium. W każdym kroku usuwamy zmienną o najwyższej wartości p (p-value przekraczającej poziom istotności alfa = 0.05, tak przyjąłem) aż do momentu, gdy w modelu pozostaną wyłącznie zmienne istotne statystycznie. Równiedobrze można zrobić to samo, ale dla statystyki t-studenta i usuwać zmienną o najmniejszej wartości statystyki t-studenta i zatrzymywać się dopiero gdy wszystkie zmienne będą mieć wartość tej statystyki >= tkrytyczne

**pogrubiony tekst - jeśli starczy czasu**
"""

from sklearn.feature_selection import SequentialFeatureSelector

X = body_fat_df.drop(['Pct.BF', 'Density'], axis=1)
y = body_fat_df['Pct.BF']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)
len(X_train)

def backward_elimination(X_train, y_train, features, alpha=0.05):
  step = 1
  print(f"{'Krok':<6} | {'Usuwana zmienna':<15} | {'Statystyka |t|':<15} | {'Wartość krytyczna'}")
  print("-" * 60)

  while True:
      X_subset = sm.add_constant(X_train[features])
      model = sm.OLS(y_train, X_subset).fit()

      # t-krytyczne dla aktualnych stopni swobody
      df = model.df_resid
      t_crit = stats.t.ppf(1 - alpha/2, df)

      t_values = model.tvalues.drop('const')

      # zmienna z najmniejszym |t|
      min_t_var = t_values.abs().idxmin()
      min_t_val = t_values.abs().min()

      # stop?
      if min_t_val < t_crit:
          print(f"{step:<6} | {min_t_var:<15} | {min_t_val:<15.4f} | {t_crit:.4f}")
          features.remove(min_t_var)
          step += 1
      else:
          print("-" * 60)
          print(f"KONIEC |t| > {t_crit:.4f}")
          break
  final_model = sm.OLS(y_train, sm.add_constant(X_train[features])).fit()

  return final_model

"""***Zaczynam eliminację!!!***"""

features = list(X_train.columns)
final_model_1 = backward_elimination(X_train, y_train, features)

print("\n=== MODEL PO ELIMINACJI ===")
print(final_model_1.summary())

features_left = final_model_1.model.exog_names[1:]
# print(features_left)

print("PREDYKCJA")
X_test_selected = X_test[features_left]
X_test_selected = sm.add_constant(X_test_selected, has_constant='add')

# X_test = X_test[features_left]
# X_test = sm.add_constant(X_test, has_constant='add')
y_pred = final_model_1.predict(X_test_selected)
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = root_mean_squared_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)

print(f"Współczynnik zmienności We: {calculate_we(y_test, y_pred, final_model_1.df_model)}")
print(f"MSE: {mse}")
print(f"MAE: {mae}")
print(f"RMSE: {rmse}")
print(f"MAPE: {mape}")

"""**Obserwacje:** Jak widać, po eliminacji zmiennych metodą statystyki |t|, zostały nam zmienne Height, Chest, Waist, Wrist. Wartość R^2 wskazuje na nieco lepsze dopasowanie modelu do danych treningowych, jest ono lepsze niż dla poprzedniego modelu z samym Abdomen. Współczynnik zmienności We = 26.98% przekracza próg 25%, wskazując na umiarkowaną precyzję predykcji a zarazem przeciętną zmienność. Razem z RMSE = 4.37% tkanki tłuszczowej i MAE = 3.50. MAPE = 36,3% potwierdza, że średni procentowy błąd wynosi około 36%. Mimo wysokiego wskaźnika uwarunkowania sugerującego współliniowość, obie zmienne są istotne statystycznie ze względu na swoje wartości p-value. Należy jednak zauważyć że rozbieżność danych z obwerwacji a danych prognozowanych jest nadal relatywnie duża dla niektórych rekordów, co może świadczyć o nienajlepszej jakości predykcji tego modelu."""

prediction_obj = final_model_1.get_prediction(X_test)
summary_table = prediction_obj.summary_frame(alpha=0.05)

df = final_model_1.df_resid  # stopnie swobody
t_crit = stats.t.ppf(1 - 0.05/2, df)

results_df = pd.DataFrame({
    'Height': X_test['Height'],
    'Chest': X_test['Chest'],
    'Waist': X_test['Waist'],
    'Wrist': X_test['Wrist'],
    'Obserwacja Pct. BF': y_test,
    'Prognoza Pct. BF': summary_table['mean'].values,
    'Bład standardowy': summary_table['mean_se'].values,
    'Przedział 95% (dolny)': summary_table['obs_ci_lower'].values, # przedzial predykcji
    'Przedział 95% (górny)': summary_table['obs_ci_upper'].values # przedzial predykcji
})

results_df.reset_index(inplace=True, drop=True)

print(f"\n\nWartość t-Studenta dla 95% przedziału: {t_crit:.3f}")
results_df

"""# ***Modele dla innych zmiennych objaśniających***
W ramach realizacji kolejnego punktu polecenia, w celu budowy modeli z innymi zmiennymi objaśniającymi, zdecydowano na przetestowanie innych metod selekcji zmiennych.

# Model z wykorzystaniem Lasso regularization
Regularyzacja polega na dodaniu kary do różnych parametrów modelu uczenia maszynowego w celu zmniejszenia nadmiernego dopasowania. W regularyzacji modelu liniowego kara jest nakładana na współczynniki, które mnożą każdy z predyktorów. Poprzez nakładanie kar, współczynniki się zerują. Metoda Lasso rozszerza klasyczną regresję liniową o karę L1 na bezwzględne wartości współczynników. Alpha parametr regularyzacji kontrolujący siłę kary. Wraz ze wzrostem alphy, Lasso "sprowadza" współczynniki do zera, dzięki temu eliminujemy nieistotne zmienne. Zmienne wejściowe trzeba ustamdaryzować, ponieważ kara działa na **bezwzględne wartości współczynników**. Bez standaryzacji zmienne o dużych skalach otrzymywałyby nieproporcjonalnie dużą karę w porównaniu do zmiennych o mniejszych skalach.

https://www.geeksforgeeks.org/machine-learning/what-is-lasso-regression/
https://medium.com/@lomashbhuva/lasso-regression-l1-regularization-explained-with-practical-examples-a2560a784af2
"""

from sklearn.linear_model import LassoCV, Lasso
from sklearn.preprocessing import StandardScaler

X = body_fat_df.drop(['Pct.BF', 'Density'], axis=1)
y = body_fat_df['Pct.BF']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

lasso_cv = LassoCV(cv=5)
lasso_cv.fit(X_train_scaled, y_train)


lasso_feats = X_train.columns[lasso_cv.coef_ != 0].tolist()
print("LASSO wybrał:", lasso_feats)

X_train_lasso = sm.add_constant(X_train[lasso_feats])
X_test_lasso = sm.add_constant(X_test[lasso_feats])
model_lasso = sm.OLS(y_train, X_train_lasso).fit()

y_pred = model_lasso.predict(X_test_lasso)
we = calculate_we(y_test, y_pred, model_lasso.df_model)

print(f"Współczynnik zmienności We: {we}")
print(f"MSE: {mean_squared_error(y_test, y_pred)}")
print(f"MAE: {mean_absolute_error(y_test, y_pred)}")
print(f"RMSE: {root_mean_squared_error(y_test, y_pred)}")
print(f"MAPE: {mean_absolute_percentage_error(y_test, y_pred)}")
print(model_lasso.summary())

"""**Obserwacje:** Jak widać, po eliminacji zmiennych metodą Lasso, zostały nam zmienne Age, Height, Neck, Abdomen, Waist, Wrist. Wartość R^2 wskazuje na nieco gorsze dopasowanie modelu do danych ~ różnica o 2,9 pkt. procentowego (model wyjaśnia 74,8% Pct. BF). Współczynnik zmienności We = 22,83% mieści się w progu 0- 25%, wskazując na dobre dopasowanie modelu do danych oraz małą zmienność.Razem z RMSE = 4,45% tkanki tłuszczowej i MAE = 3,63. MAPE = 21,4% potwierdza, że średni procentowy błąd wynosi około 21%. Świadczy to o dość dobrej jakości predykcji. LASSO skutecznie zredukował liczbę zmiennych objaśniającyh do 6, poprawiając tym samym We o ~4,16 pp, ale problem współliniowości Abdomen/Waist wymaga dalszych działań.

# Forwad Selection
Polega na stopniowym dodawaniu zmiennych objaśniających,
zaczynając od modelu bez predyktorów. Na każdym kroku wybierana jest zmienna,
która maksymalizuje **Adjusted R²** modelu. Proces zatrzymuje się, gdy dodanie
kolejnej zmiennej nie poprawia już Adjusted R².

Kryterium: Adjusted R^2_adj = 1 - [(1-R^2)(n-1)/(n-p-1)]
gdzie: n = liczba obserwacji, p = liczba predyktorów
"""

def forward_selection_r2(X_train, y_train, features):
    step = 1
    selected_features = []
    remaining_features = list(features)

    print(f"{'Krok':<6} | {'Dodawana zmienna':<15} | {'Adj R^2':<12} | {'Delta Adj R^2'}")
    print("-" * 55)

    while remaining_features:
        best_adj_r2 = -float('inf')
        best_feature = None
        best_improvement = 0

        for feature in remaining_features:
            current_features = selected_features + [feature]
            X_subset = sm.add_constant(X_train[current_features])
            model = sm.OLS(y_train, X_subset).fit()

            if model.rsquared_adj > best_adj_r2:
                best_adj_r2 = model.rsquared_adj
                best_feature = feature

        if best_feature is None:
            break

        prev_features = selected_features.copy()
        if len(prev_features) > 0:
            X_prev = sm.add_constant(X_train[prev_features])
            prev_model = sm.OLS(y_train, X_prev).fit()
            best_improvement = best_adj_r2 - prev_model.rsquared_adj

            if best_improvement <= 0:
                print(f"{step:<6} | BRAK POPRAWY | {best_adj_r2:<12.4f} | {best_improvement:+.4f}")
                break

        selected_features.append(best_feature)
        remaining_features.remove(best_feature)

        print(f"{step:<6} | {best_feature:<15} | {best_adj_r2:<12.4f} | {best_improvement:+.4f}")
        step += 1

    print("-" * 55)
    print(f"KONIEC - wybrane: {selected_features}")

    final_model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()
    return final_model, selected_features

X = body_fat_df.drop(['Pct.BF', 'Density'], axis=1)
y = body_fat_df['Pct.BF']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90)

final_model_2, selected_features = forward_selection_r2(X_train, y_train, list(X_train.columns))

print("MODEL PO FORWARD SELECTION")
print(final_model_2.summary())

print("PREDYKCJA")
X_test_selected = X_test[selected_features]
X_test_selected = sm.add_constant(X_test_selected)
y_pred = final_model_2.predict(X_test_selected)

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = root_mean_squared_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)

print(f"Wybrane zmienne: {selected_features}")
print(f"MSE:  {mse}")
print(f"MAE:  {mae}")
print(f"RMSE: {rmse}")
print(f"MAPE: {mape}")
print(f"We:   {calculate_we(y_test, y_pred, final_model_2.df_model)}")

"""**Obserwacje:** Jak widać, po eliminacji zmiennych metodą Forward Selection, zostały nam zmienne Waist, Wrist, Weight, Forearm, Neck, Age, Bicep, Ankle. Wartość R^2 wskazuje na nieco lepsze dopasowanie modelu do danych niż model z regularyzacją. Współczynnik zmienności We = 23,40% mieści się w progu 0-25%, wskazując na dobre dopasowanie modelu do danych, małą zmienność. Razem z RMSE = 4,46% tkanki tłuszczowej i MAE = 3,63. MAPE = 21,3% potwierdza, że średni procentowy błąd wynosi około 21%. Świadczy to o nieco lepszej jakości predykcji w porównaniu z poprzednimi modelami."""