# -*- coding: utf-8 -*-
"""Lab-2-Zad-3-Michał-Ślęzak-Szymon-Oleśkiewicz

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aUw_1s-62GefoAwS-hrYgUTSez5aw3GB
"""

import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns

"""# Przygotowanie danych i EDA"""

np.random.seed(45)

cereal_df = pd.read_csv('Płatki-sniadaniowe-cereals.txt', sep="\t")
cereal_df

cereal_df.isna().sum()

cereal_df.duplicated().sum()

cereal_df.info()

cereal_df.describe()

cereal_df = cereal_df.drop(['nazwa', 'producent', 'srodk_polka', 'Liczba_polek'], axis=1) # niepotrzebne z punktu widzenia modelu
plt.figure(figsize=(10,8))
sns.heatmap(cereal_df.corr(), annot=True, cmap='coolwarm', center=0, fmt='.2f')
plt.title('Macierz korelacji')
plt.show()

"""**Obserwacje:** Z analizy macierzy korelacji wynika, że półka 2 ma największą korelację ujemną z potasem, błonnikiem i białkiem, natomiat wysoką korelację dodatnią z cukrem, co może sugerować, że na półce 2 są płatki o najgorszym składzie, niezdrowe, których sklep chce się szybko pozbyć.

Półka 3 ma największą korelację dodatnią z potasem, błonnikiem i białkiem natomiast wysoką korelację ujemną z cukrem, co może sugerować, że na półce 3 będą płatki o najlepszym składzie, tj. największej zawartości błonnika, potasu czy białka.

Półka 1 nie ma jednoznacznej korelacji ze składem, ma największą korelację ujemną z cukrem czy tłuszczem ale tak samo ma korelację ujemną z błonnikiem czy potasem a z białkiem korelacja jest  dodatnia (największa dodatnia jest z węglowodanami). Można przypuszczać, że na tej półce będą płatki z wysoką zawartością węglowodanów, ale niską zawartością cukrów, gdyż te dwie zmienne mają skrajne, największe przeciwne korelacje z półką 1.

Widoczna jest także dość wysoka korelacja między zmiennymi: potas-błonnik-białko oraz cukier-kalorie.

Mając na uwagę wartość biznesową, ludzie przeważnie patrzą w składzie na cukier, kalotie, białko, błonnik i potas.

# Modelowanie
**a)** przeanalizować dane i zastanowić się nad tym „Co chcemy zbadać i dlaczego?”,
tzn. na jakie pytania chcemy sobie odpowiedzieć:


1.   Czy skład płatków ma wpływ na ich umiejscowienie na półce w sklepie (1, 2 czy 3 półka)?
2.   Czy płatki lepsze, zdrowsze, tj. np. z wyższą zawartością białka, potasu czy błonnika są umiejscowione wyżej ??
3.   Czy na półce środkowej są płatki gorsze jakościowo, których sklep chce się jak najszybciej pozbyć?
4. Jakie płatki umieszczane są na najniższej półce?

# Model dla półki 2
Półka znajduje się, zazwyczaj, na wysokości wzroku dzieci i w zasięgu ręki dorosłego szukającego szybkiego wyboru (niekoniecznie najzdrowszego). Sugerując się macierzą korelacji, na tej półce są najprawdopodobniej płatki gorszej jakości, które sklep chce nam opchnąć szybko.
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc
from sklearn.model_selection import train_test_split

features = cereal_df.columns.tolist()
features.remove('polka_1')
features.remove('polka_2')
features.remove('polka_3') # mozna szybciej, ale no ...
# print(features)

X_all_features = cereal_df[features]

def build_cereal_shelf_model(shelf_name, selected_features, roc=False): # trzeba sobie ułatwiać życie ;)
  X = X_all_features[selected_features]
  X = sm.add_constant(X)
  y = cereal_df[shelf_name]

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)

  model = sm.Logit(y_train, X_train).fit()

  y_pred_probability = model.predict(X_test)
  y_pred_binary = (y_pred_probability > 0.5).astype(int)

  conf_m = confusion_matrix(y_test, y_pred_binary)
  tn, fp, fn, tp = conf_m.ravel()
  specifity = tn / (tn + fp)


  print(f"{'='*20} Model dla półki: {shelf_name} i zmiennych {selected_features} {'='*20}")
  print(model.summary())

  print(conf_m.tolist())
  print(f"Dokładność: {accuracy_score(y_test, y_pred_binary)}")
  print(f"Precyzja: {precision_score(y_test, y_pred_binary)}")
  print(f"Czułość: {recall_score(y_test, y_pred_binary)}")
  print(f"Specyficzność: {specifity}")
  print(f"F1: {f1_score(y_test, y_pred_binary)}")
  print(f"AUC: {roc_auc_score(y_test, y_pred_probability)}")

  if roc:
    # krzywa ROC
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probability)  # False Positive Rate, True Positive Rate dla wszystkich progów
    roc_auc = auc(fpr, tpr)  # pole pod krzywą

    optimal_idx = np.argmax(tpr - fpr)  # max odleglosc, bo chce max true positive i najmniejsze false positive
    optimal_threshold = thresholds[optimal_idx]
    optimal_fpr = fpr[optimal_idx]
    optimal_tpr = tpr[optimal_idx]

    print(f"Najlepszy próg: {optimal_threshold:.3f}")


    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Krzywa ROC (AUC = {roc_auc:.3f})')
    plt.scatter(optimal_fpr, optimal_tpr, color='red', label=f"Punkt optymalny ({round(optimal_fpr, 3)}, {round(optimal_tpr, 3)})")
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Klasyfikator losowy')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.02])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Krzywa ROC - Model logitowy')
    plt.legend(loc="lower right")
    plt.grid(True, alpha=0.3)
    plt.show()

  return model

"""**cukry** - chcemy sprawdzić czy wysoka zawartość cukru, jako niezdrowy składnik, jest jedynym czynnikiem, który sprawia, że dane płatki trafiają na tą półkę, co potwierdzałoby przyciąganie np. dzieci."""

model_1 = build_cereal_shelf_model("polka_2", ["cukry"])

"""**cukry + kalorie** - chcemy sprawdzić czy płatki wysokokaloryczne i słodkie są celowo umieszczane na tej półce, aby, np. pod wpływem impulsu, ludzie kupowali je jako szybki wybór na śniadanie, jako zastrzyk energii."""

model_2 = build_cereal_shelf_model("polka_2", ["cukry", "kalorie"])

"""**cukry + kalorie + potas + białko + błonnik** - chcemy sprawdzić czy na tej konkretnej półce liczy się tylko ten najgorszy skład (cukier/kalorie) czy może obecność zdrowszych składników też ma na to wpływ co sklep chce nam opchnąć."""

model_3 = build_cereal_shelf_model("polka_2", ["cukry", "kalorie", "potas", "proteiny", "blonnik"])

"""**cukier + białko**"""

model_additional = build_cereal_shelf_model("polka_2", ["cukry", "proteiny"])

"""**Obserwacje:** Na postawie analizy wyników zbudowanych modeli można stwierdzić, że żaden nie jest idealny. Jedynym modelem, którego metryki oceny są wysokie to model oparty tylko o cukier, co sugerowała również macierz korelacji (dodatnia korelacja). Model ten charakteryzuje się wysoką czułością (~ 75%) oraz najwyższym AUC (~ 66,7%) i wskaźniekiem najwyższym F1 (~0,667). Ponadto, jest to model, w którym zmienna cukier jest istotna statystycznie (p-value < 0,05 --- test Walda), w pozostałych modelach, wszystkie inne zmienne poza cukrem, które są w modelu, sugerują nieistotność statystyczną ze względu na wartości >= 0,05.

# Model dla półki 3
Góna półka wymaga od klienta, zazwyczaj, wysiłku. Dlatego, mając na uwagę macierz korelacji, najprawdopodobniej na tej półce są płatki najzdrowsze, tj. z wysoką zawartością białka, potasu i błonnika.

**błonnik + potas + białko** - chcemy sprawdzic czy wysoka zawartość mieszanki zdrowych składników determinuje umijescowienie płatków na 3 półce. Wiele osób, które prowadzą zdrowy tryb życia patrzą też łącznie na zawartość białka -> błonnika -> potasu, dlatego ten model wydaje się być się istotny z perspektywy biznesowej (wybór zdrowych płatków przez klientów)
"""

model_4 = build_cereal_shelf_model("polka_3", ["potas", "proteiny", "blonnik"])

"""**potas + błonnik** - sprawdzenie czy tylko składniki mineralne mają wpływ na umiejscowienie płatków na 3 półce."""

model_5 = build_cereal_shelf_model("polka_3", ["potas", "blonnik"])

"""**potas + białko** - sprawdzenie czy składnik budulcowy mięśni i minerał wystarczą, aby płatki były na 3 półce."""

model_6 = build_cereal_shelf_model("polka_3", ["potas", "proteiny"])

"""**błonnik + białko** - sprawdzenie czy składnik budulcowy mięśni i minerał dający uczucie sytości wystarczą, aby płatki były na 3 półce."""

model_7 = build_cereal_shelf_model("polka_3", ["proteiny", "blonnik"])

"""**białko** - sprawdzenie czy wysoka zawartość materaiłu budulcowego mięśni - białka wystarczy, aby płatki były na 3 półce, jest to podyktowane tym, że nie któe osoby prowadzący aktywny tryb życia, np. poprzez trenowanie siłowe, patrzą tylko na zawartość białka."""

model_8 = build_cereal_shelf_model("polka_3", ["proteiny"])

"""**potas** - sprawdzenie czy tylko ten minerał ma wpływ największy na umiejscowienie na półce 3, bo poprzedni model z potasem i białkiem wykazał, że potas jako jedyny jest istotny statystycznie i jest silnie skorelowany z błonnikiem.

Zdecydowano się na budowę tego modelu ze względu na to, że wcześniejszy model oparty o potas i białko miał najlepsze metryki w porównaniu z innymi dotychczasowymi modelami i zmienna potas jako jedyna była istotna statystycznie w tym modelu (model z błonnikiem też wykazał istotność tego składnika, ale model z potasem i białkiem miał lepsze metryki).
"""

model_potas = build_cereal_shelf_model("polka_3", ["potas"])

"""**Obserwacje:** Najlepszym modelem dla półki 3 okazał się model oparty na potasie. Wykazuje on najwyższą istotność statystyczną dla zmiennej potas. Modele zawierające jednocześnie potas i błonnik charakteryzują się wysokim wartościami p-value co może świadczyć o ich multikolinearności, co pokazuje też macierz korelacj (0,90). Model dla potasu i protein posiada wysoki AUC (~ 0,75, minimalnie mniejszy od modelu opartego tylko o potas) i minimalnie większą metrykę Pseudo R^2, natomiast współczynnik czy białku jest ujemny, co nie do końca wpasowuje się w nasze zadane pytania i macierz korelacji. Dlatego właśnie model oparty tylko o potas wydaje się być najlepszy, mimo, że nie ma on idealnych metryk. Analiza wyników zbudowanych modeli pozwala stwierdzić, że na półce 3 rzeczywiście znajdują się płątki zdrowsze, przede wszystkim z wysoką zawartością skłądnika mineralnego jakim jest potas.

# Model dla półki 1
Macierz korelacji nie wykazała konkretnych silnych zależności między składnikami jesli chodzi o umiejscowienie płatków na półce 1.
Dlatego zdecydowano się na sprawdzenie modeli opartych o zmienne, które z punktu widzenia klienta mogą być istotne.

węglowodany - produkty zbożowe oparte np. na skrobii ? Dodatnia korelacja.
cukier - mniejsza zawartość cukru - brak atrakcyjności dla, np. dzieci ? Ujemna korelacja.

**węglowodany**
"""

model_9 = build_cereal_shelf_model("polka_1", ["weglowodany"])

"""**cukry**"""

model_10 = build_cereal_shelf_model("polka_1", ["cukry"])

"""**węglowodany + cukry**"""

model_11 = build_cereal_shelf_model("polka_1", ["weglowodany", "cukry"])

"""**wszystkie zmienne**"""

model_12 = build_cereal_shelf_model("polka_1", features)

"""**Obserwacje:**
Na podstawie przeprowadzonych obliczeń oraz wcześniejszej analizy macierzy korelacji, należy stwierdzić, że nie udało się zbudować modelu o wysokiej zdolności klasyfikacyjnej dla półki 1.

Bardzo niskie (0) wartości metryk precyzji, czułości i F1 oraz wysokie wartości p-value w modelach wielozmiennych dowodzą, że w badanym zbiorze danych nie istnieją silne i powtarzalne zależności między składem odżywczym a umieszczeniem płatków na dolnej półce. Potwierdza to wstępną analizę macierzy korelacji, która nie wykazała żadnego składnika wyraźnie powiązanego z tą półką. Słabe wyniki modeli sugerują, że o lokowaniu produktów na samym dole regału decydują czynniki inne niż wartości odżywcze. Najprawdopodobniej są to kryteria logistyczne (np. gabaryty opakowań) lub ekonomiczne (najniższa cena, produkty marek własnych itp. itd.).

# Wyłączenie danego producenta i weryfikacja poprawności klasyfikacji dla najlepszych modeli z danej półki

Zrezygnowano z powyższego kroku dla półki 1 ze względu na brak wykrytych jakichkolwiek jednoznacznych zależności między składem a umiejscowieniem na półce 1.

**Sprawdzenie liczności płatków danego producenta - wyłączamy producenta z największą liczbą płatków, żeby mieć na czym sprawdzać potem**
"""

cereal_verify_df = pd.read_csv('Płatki-sniadaniowe-cereals.txt', sep="\t")
new_cereal_df = cereal_verify_df.copy()
cereal_verify_df

cereal_agg_df = cereal_verify_df.groupby(["producent"])["producent"].count()
cereal_agg_df

# cereal_verify_test_df =  cereal_verify_df[cereal_verify_df["producent"] == 'K'].drop(['nazwa', 'producent', 'srodk_polka', 'Liczba_polek'], axis=1)
# cereal_verify_df = cereal_verify_df[cereal_verify_df["producent"] != 'K'].drop(['nazwa', 'producent', 'srodk_polka', 'Liczba_polek'], axis=1)
# cereal_verify_df.head()

# cereal_verify_test_df.head()

# MOZNA OCZYWISCIE DOSTOSOWAC POPRZEDNIA FUNKCJE, KTORA JEST WYZEJ, ALE JA ZDECYDOWALEM ZROBIC NOWA PO PROSTU TYLKO DO TEGO EKSPERYMENTU
def build_cereal_shelf_model(shelf_name, selected_features, mfr_to_kick, roc=False, threshold=0.5): # trzeba sobie ułatwiać życie ;)

  cereal_verify_test_df =  new_cereal_df[new_cereal_df["producent"] == mfr_to_kick].drop(['nazwa', 'producent', 'srodk_polka', 'Liczba_polek'], axis=1)
  cereal_verify_df = new_cereal_df[new_cereal_df["producent"] != mfr_to_kick].drop(['nazwa', 'producent', 'srodk_polka', 'Liczba_polek'], axis=1)

  features = cereal_verify_df.columns.tolist()
  features.remove('polka_1')
  features.remove('polka_2')
  features.remove('polka_3') # mozna szybciej, ale no ...
  # print(features)

  X_all_features_train = cereal_verify_df[features]
  X_all_features_test = cereal_verify_test_df[features]

  X_train = X_all_features_train[selected_features]
  X_train = sm.add_constant(X_train)
  y_train = cereal_verify_df[shelf_name]

  X_test = X_all_features_test[selected_features]
  X_test = sm.add_constant(X_test)
  y_test = cereal_verify_test_df[shelf_name]


  model = sm.Logit(y_train, X_train).fit()

  y_pred_probability = model.predict(X_test)
  y_pred_binary = (y_pred_probability > threshold).astype(int)

  conf_m = confusion_matrix(y_test, y_pred_binary)
  tn, fp, fn, tp = conf_m.ravel()
  specifity = tn / (tn + fp)

  df_results = X_test.copy()
  df_results['rzeczywista'] = y_test
  df_results['prawdopodobienstwo'] = y_pred_probability.round(2)
  df_results['predykcja'] = y_pred_binary

  df_results['wynik'] = df_results.apply(lambda x: 'OK' if x['rzeczywista'] == x['predykcja'] else 'BŁĄD', axis=1)


  print(" WERYFIKACJA KLASYFIKACJI DLA PRODUCENTA 'K' ")
  display_cols = selected_features + ['rzeczywista', 'predykcja', 'prawdopodobienstwo', 'wynik']
  print(df_results[display_cols].to_string(index=True))


  print(f"{'='*20} Model dla półki: {shelf_name} i zmiennych {selected_features} {'='*20}")
  print(model.summary())

  print(conf_m.tolist())
  print(f"Dokładność: {accuracy_score(y_test, y_pred_binary)}")
  print(f"Precyzja: {precision_score(y_test, y_pred_binary)}")
  print(f"Czułość: {recall_score(y_test, y_pred_binary)}")
  print(f"Specyficzność: {specifity}")
  print(f"F1: {f1_score(y_test, y_pred_binary)}")
  print(f"AUC: {roc_auc_score(y_test, y_pred_probability)}")

  if roc:
    # krzywa ROC
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probability)  # False Positive Rate, True Positive Rate dla wszystkich progów
    roc_auc = auc(fpr, tpr)  # pole pod krzywą

    optimal_idx = np.argmax(tpr - fpr)  # max odleglosc, bo chce max true positive i najmniejsze false positive
    optimal_threshold = thresholds[optimal_idx]
    optimal_fpr = fpr[optimal_idx]
    optimal_tpr = tpr[optimal_idx]

    print(f"Najlepszy próg: {optimal_threshold:.3f}")


    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Krzywa ROC (AUC = {roc_auc:.3f})')
    plt.scatter(optimal_fpr, optimal_tpr, color='red', label=f"Punkt optymalny ({round(optimal_fpr, 3)}, {round(optimal_tpr, 3)})")
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Klasyfikator losowy')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.02])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Krzywa ROC - Model logitowy')
    plt.legend(loc="lower right")
    plt.grid(True, alpha=0.3)
    plt.show()


  return model

"""# Półka 3"""

model_pot_verify = build_cereal_shelf_model("polka_3", ["potas"], 'K', roc=True)

model_pot_verify = build_cereal_shelf_model("polka_3", ["potas"], 'K', threshold=0.3)

"""**Dodatkowe wnioski:** Po wyłączeniu z danych treningowych producenta o największej liczbie płatków w zbiorze danych, zbudowane modele całkiem dobrze sobie radzą z klasyfikacją płatków tych producentów na półce 3. Zmienne w obu modelach są istotne statystycznie. Dla pierwszego modelu i producenta K, zdolność modelu do klasyfikacji płatków na półce 3 charakteryzuje się wyższą zdolnością do klasyfikacji wykluczającej należenie do półki 3 niż że należą aczkolwiek F1 jest na poziomie 0.7, co jest całkiem dobrym wynikiem.

Dzięki zastosowaniu optymalnego progu klasyfikacji wyznaczonego metodą krzywej ROC, udało się zwiększyć czułość modelu o 25 punktów procentowych. Oznacza to, że model znacznie lepiej radzi sobie z wykrywaniem produktów, które faktycznie powinny znaleźć się na 3. półce (a na tym nam zależy), kosztem jedynie niewielkiego spadku specyficzności. Należy jednak zauważyć, że specyficzność i czułość są zbliżne oraz wartość F1 jest dość wysoka, co świadczy o poprawie skuteczności modelu.

Zbudowane modele wykazują wysoką zdolność do generalizacji, po wyłączeniu kluczowego producenta ze zbioru treningowego, algorytm wciąż poprawnie klasyfikuje większość danych dla danego producenta.

W modelach logitowych wartości Pseudo R^2 (McFadden) rzędu 0.2-0.4 są uznawane za bardzo dobre dopasowanie. Wynik w okolicy 0.16, przy tak małej próbie i tylko jednej zmiennej objaśniającej, należy uznać za satysfakcjonujący i potwierdzający istotność potasu jako predyktora klasyfikującego płatki na półkę 3.

# Półka 2
"""

model_sug_verify = build_cereal_shelf_model("polka_2", ["cukry"], 'K', roc=True)

model_sug_verify = build_cereal_shelf_model("polka_2", ["cukry"], 'K', threshold=0.25)

"""**Dodatkowe wnioski:** Model logitowy dla polki 2 oparty na zmiennej cukier wykazuje znacznie słabsze właściwości klasyfikacyjne niż modele dla polki 3.
Niska wartość Pseudo R^2 (poniżej 0,12) oraz niska czułość sugerują, że zawartość cukru nie jest uniwersalnym predyktorem lokalizacji produktu dla tej półki i producenta. Analiza błędów dla producenta K pokazuje, że model systematycznie zaniża prawdopodobieństwo przynależności do 2. półki. Świadczy to o tym, że strategia lokowania słodkich produktów producenta K jest specyficzna i model de facto wyuczony na konkurencji nie potrafi jej w pełni zrekonstruować.

Po zmianie progu klasyfikacji dla półki 2 zauważono znaczącą poprawę jakości modelu. Niskie wartości czułości czy F1 sugerowały, że model logitowy poprawnie wyklucza produkty według zawartości cukru, ale standardowy próg 0.5 nie był optymalny.

Po zmianie progu na 0,25, model osiągnął pełną czułość (1,0) przy wysokim wskaźniku F1 (0,70). Podczas gdy model wyuczony na innych firmach oczekuje bardzo wysokich wartości cukru dla 2. półki, producent K umieszcza tam produkty już przy znacznie niższych stężeniach tej substancji. Optymalizacja progu pozwoliła na poprawę jakości klasyfikacji modelu jednakże nie jest to najlepszy model, m.in. poprzez małą liczność zbioru danych, co po wyłączeniu producenta sprawia, że model ten jest gorszy od poprzednich i zmienna cukier nie jest istotna statystycznie.
"""

