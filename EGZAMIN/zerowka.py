# -*- coding: utf-8 -*-
"""ZERÓWKA-GOD-BLESS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l58gPAXBJ0eeprxFqaCyFm-T_w505IKu
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

np.random.seed(45)

body_fat_df = pd.read_csv('Lab-1-Zadanie-2-Dane.txt', sep="\t")

body_fat_df.head()

plt.figure(figsize=(10,8))
sns.heatmap(body_fat_df.corr(), annot=True, cmap='coolwarm', center=0, fmt='.2f')
plt.title('Macierz korelacji')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, mean_absolute_percentage_error
import statsmodels.api as sm
from sklearn.linear_model import LassoCV, Lasso, Ridge, RidgeCV, ElasticNet, ElasticNetCV
from sklearn.preprocessing import StandardScaler

def calculate_std(y_test, y_pred, df):
    sse = np.sum((y_test - y_pred) ** 2)
    df_total = len(y_test) - df - 1
    # print(len(y_test), df)
    return np.sqrt(sse / df_total)


def calculate_we(y_test, y_pred, df):
  return (calculate_std(y_test, y_pred, df) / np.mean(y_test)) * 100

"""# Najpierw bodyfat!

***STANDARYZACJA FIRST!!! BO MAMY RÓŻNE SKALE I WSPÓŁCZYNNIKI NIEPROPORCJONALNE KARY BY DOSTAWAŁY. Bez standaryzacji zmienne o dużych skalach otrzymywałyby nieproporcjonalnie dużą karę w porównaniu do zmiennych o mniejszych skalach.***
"""

X = body_fat_df.drop(['Pct.BF'], axis=1) # zostawiam density, zgodnie z tym co Pan Profesor mówił na labach :)
y = body_fat_df['Pct.BF']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train) # ucze sie treningowych (liczy srednia, odchylenie, zeby ustandaryzowac) i przeskalowuje
X_test_scaled = scaler.transform(X_test) # przeskalowuje tylko

"""**LASSO poraz 2 ;)**"""

lasso_cv = LassoCV(cv=5)
lasso_cv.fit(X_train_scaled, y_train)

lasso_feats = X_train.columns[lasso_cv.coef_ != 0].tolist()
print("LASSO wybrał:", lasso_feats)

X_train_lasso = sm.add_constant(X_train[lasso_feats])
X_test_lasso = sm.add_constant(X_test[lasso_feats])

model_lasso = sm.OLS(y_train, X_train_lasso).fit()

y_pred = model_lasso.predict(X_test_lasso)
we = calculate_we(y_test, y_pred, model_lasso.df_model)

print(f"Współczynnik zmienności We: {we}")
print(f"MSE: {mean_squared_error(y_test, y_pred)}")
print(f"MAE: {mean_absolute_error(y_test, y_pred)}")
print(f"RMSE: {root_mean_squared_error(y_test, y_pred)}")
print(f"MAPE: {mean_absolute_percentage_error(y_test, y_pred)}")
print(model_lasso.summary())

"""**Można było się tego spodziewać, że zostanie, m.in. Density, Abdomen i Waist, bo one są silnie skorelowane z bodyfatem, na podstawie macierzy korelacji + Age tez ma korelacje z bodyfatem, ale nie tak silną jak te wspomniane wyżej + o wiele lepsze dopasowanie na podstawie We poronujac je z wartoscia z pierwotnego sprawozdania naszego**

**Ridge poraz 1 ;)**
"""

ridge_cv = RidgeCV(cv=5)
ridge_cv.fit(X_train_scaled, y_train)

# ridge_feats = X_train.columns[ridge_cv.coef_ != 0].tolist()
# print("RIDGE wybrał:", ridge_feats)

# tu się zaczyna ciekawie, bo wszystkie są !=0, więc posortuje je rosnaco i dokonam selekcji top 5 np.
coefs = pd.Series(ridge_cv.coef_, index=X_train.columns)
ridge_significance = coefs.abs().sort_values(ascending=False) # interesuje na "siła zależności"

ridge_significance.head(5)
# print(coefs.loc[ridge_significance.index])

ridge_feats = ridge_significance.index.tolist()[:5]
ridge_feats

X_train_ridge = sm.add_constant(X_train[ridge_feats])
X_test_ridge = sm.add_constant(X_test[ridge_feats])

model_ridge = sm.OLS(y_train, X_train_ridge).fit()
y_pred = model_ridge.predict(X_test_ridge)
we = calculate_we(y_test, y_pred, model_ridge.df_model)

print(f"Współczynnik zmienności We: {we}")
print(f"MSE: {mean_squared_error(y_test, y_pred)}")
print(f"MAE: {mean_absolute_error(y_test, y_pred)}")
print(f"RMSE: {root_mean_squared_error(y_test, y_pred)}")
print(f"MAPE: {mean_absolute_percentage_error(y_test, y_pred)}")
print(model_ridge.summary())

"""**Again, można było się spodziewać, że zostaną, m.in. Density, Waist i Abdomen ze względu na silną korelację, troche wyzsze We od Lasso, ale bardzo dobre dopasowanie pokazuje, bo jest lepsze od tego z pierwotnego sprawozdania + te inne zmienne tez maja korelacje z bodyfatem, ale nie tak silną jak te 3 wspomniane wyżej**

**Elastic Net poraz 1 ;)**
"""

elastic_net_cv = ElasticNetCV(cv=5, l1_ratio=[.1, .5, .7, .9, .95, .99, .5])
elastic_net_cv.fit(X_train_scaled, y_train)

elastic_feats = X_train.columns[elastic_net_cv.coef_ != 0].tolist()
print("ELEASTIC NET wybrał:", elastic_feats)

X_train_elastic = sm.add_constant(X_train[elastic_feats])
X_test_elastic = sm.add_constant(X_test[elastic_feats])

model_elastic_net = sm.OLS(y_train, X_train_elastic).fit()

y_pred = model_elastic_net.predict(X_test_elastic)
we = calculate_we(y_test, y_pred, model_elastic_net.df_model)

print(f"Współczynnik zmienności We: {we}")
print(f"MSE: {mean_squared_error(y_test, y_pred)}")
print(f"MAE: {mean_absolute_error(y_test, y_pred)}")
print(f"RMSE: {root_mean_squared_error(y_test, y_pred)}")
print(f"MAPE: {mean_absolute_percentage_error(y_test, y_pred)}")
print(model_elastic_net.summary())

"""**Dostalismy ten sam wynik de facto jak dla czystego Lasso, co dowodzi ze jest on dobrym modelem, jest to potwierdzenie dla nas de facto, bo nawet wartosci bledow obliczonych sa mniejsze!!!**

# Potem density!!
"""

X = body_fat_df.drop(['Density'], axis=1)
y = body_fat_df['Density']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train) # ucze sie treningowych (liczy srednia, odchylenie, zeby ustandaryzowac) i przeskalowuje
X_test_scaled = scaler.transform(X_test) # przeskalowuje tylko

"""**Lasso**"""

lasso_cv = LassoCV(cv=5)
lasso_cv.fit(X_train_scaled, y_train)

lasso_feats = X_train.columns[lasso_cv.coef_ != 0].tolist()
print("LASSO wybrał:", lasso_feats)

X_train_lasso = sm.add_constant(X_train[lasso_feats])
X_test_lasso = sm.add_constant(X_test[lasso_feats])

model_lasso = sm.OLS(y_train, X_train_lasso).fit()

y_pred = model_lasso.predict(X_test_lasso)
we = calculate_we(y_test, y_pred, model_lasso.df_model)

print(f"Współczynnik zmienności We: {we}")
print(f"MSE: {mean_squared_error(y_test, y_pred)}")
print(f"MAE: {mean_absolute_error(y_test, y_pred)}")
print(f"RMSE: {root_mean_squared_error(y_test, y_pred)}")
print(f"MAPE: {mean_absolute_percentage_error(y_test, y_pred)}")
print(model_lasso.summary())

"""**Ridge**"""

ridge_cv = RidgeCV(cv=5)
ridge_cv.fit(X_train_scaled, y_train)

# ridge_feats = X_train.columns[ridge_cv.coef_ != 0].tolist()
# print("RIDGE wybrał:", ridge_feats)

# tu się zaczyna ciekawie, bo wszystkie są !=0, więc posortuje je rosnaco i dokonam selekcji top 5 np.
coefs = pd.Series(ridge_cv.coef_, index=X_train.columns)
ridge_significance = coefs.abs().sort_values(ascending=False) # interesuje na "siła zależności"

ridge_significance.head(5)
# print(coefs.loc[ridge_significance.index])

ridge_feats = ridge_significance.index.tolist()[:5]
ridge_feats

X_train_ridge = sm.add_constant(X_train[ridge_feats])
X_test_ridge = sm.add_constant(X_test[ridge_feats])

model_ridge = sm.OLS(y_train, X_train_ridge).fit()
y_pred = model_ridge.predict(X_test_ridge)
we = calculate_we(y_test, y_pred, model_ridge.df_model)

print(f"Współczynnik zmienności We: {we}")
print(f"MSE: {mean_squared_error(y_test, y_pred)}")
print(f"MAE: {mean_absolute_error(y_test, y_pred)}")
print(f"RMSE: {root_mean_squared_error(y_test, y_pred)}")
print(f"MAPE: {mean_absolute_percentage_error(y_test, y_pred)}")
print(model_ridge.summary())

"""istotnosc abdomen ? pct bodyfat zaburza ?

**Elastic Net**
"""

elastic_net_cv = ElasticNetCV(cv=5, l1_ratio=[.1, .5, .7, .9, .95, .99, .5])
elastic_net_cv.fit(X_train_scaled, y_train)

elastic_feats = X_train.columns[elastic_net_cv.coef_ != 0].tolist()
print("ELEASTIC NET wybrał:", elastic_feats)

X_train_elastic = sm.add_constant(X_train[elastic_feats])
X_test_elastic = sm.add_constant(X_test[elastic_feats])

model_elastic_net = sm.OLS(y_train, X_train_elastic).fit()

y_pred = model_elastic_net.predict(X_test_elastic)
we = calculate_we(y_test, y_pred, model_elastic_net.df_model)

print(f"Współczynnik zmienności We: {we}")
print(f"MSE: {mean_squared_error(y_test, y_pred)}")
print(f"MAE: {mean_absolute_error(y_test, y_pred)}")
print(f"RMSE: {root_mean_squared_error(y_test, y_pred)}")
print(f"MAPE: {mean_absolute_percentage_error(y_test, y_pred)}")
print(model_elastic_net.summary())

"""**Generalnie to te modele są o wiele gorsze jesli pod uwage wezmiemy tylko We, bo przekracza ona poziom bardzo dobrego dopasowania modelu do danych (>25%, ale < 45%, co oznacza przecietna zmiennosc). Wspolczynnik determinacji mowi o bardzo dobrym dopasownaiu modelu do danych, ale jest od jednak troche mniejszy niz te w modelach przewidujacych bodyfat. Model oparty o regularyzacje jest jednak troche lepszy, ma mniejsze wartosci bledow, co potrwierrdzil tez elastic net, bo dostalismy de facto ten sam model co w czystym lasso. W modelach jest m.in. zmienna pct bodyfat, czego mozna bylo sie spodziewaqc ze wzgledu na silna korelacje jej z density, na podstawie macierzy korelacji. Zmienna height w modelu z lasso nie ma duzej korelacji z density, wiec mozna przypuiszcacm, ze bodyfat ma najwiekszy wplyw na nia. Natonmiast w modxelu z ridge, mozna bylo sie spodziewac, ze oprocz pct bodyfat pojawia sie zmienne tez abdomen, gdyz jest ona silnie skorelowana ze zmeinna objasniana, pozostale zmienne tez maja korelacje z density, aczkolwiek jest ona mniejsza niz ta miedzy abdomen a density**"""

